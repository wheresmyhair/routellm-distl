INFO 04-10 06:20:58 [__init__.py:239] Automatically detected platform cuda.
INFO:lm_eval.__main__:Selected Tasks: ['ifeval']
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.2-1B-Instruct'}
INFO:lm_eval.models.huggingface:Using device 'cuda'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
INFO:lm_eval.evaluator:ifeval: Using gen_kwargs: {'until': [], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 1280}
INFO:lm_eval.evaluator:num_fewshot has been set to 0 for ifeval in its config. Manual configuration will be ignored.
INFO:lm_eval.api.task:Building contexts for ifeval on rank 0...
  0%|          | 0/541 [00:00<?, ?it/s]100%|██████████| 541/541 [00:00<00:00, 131322.33it/s]
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/541 [00:00<?, ?it/s]/home/yizhenjia/anaconda3/envs/lmeval/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/yizhenjia/anaconda3/envs/lmeval/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   0%|          | 1/541 [00:56<8:29:57, 56.66s/it]Running generate_until requests:  24%|██▍       | 129/541 [01:38<04:19,  1.59it/s]Running generate_until requests:  48%|████▊     | 257/541 [02:18<02:07,  2.24it/s]Running generate_until requests:  71%|███████   | 385/541 [02:59<01:00,  2.58it/s]Running generate_until requests:  95%|█████████▍| 513/541 [03:13<00:07,  3.57it/s]Running generate_until requests: 100%|██████████| 541/541 [03:13<00:00,  2.79it/s]
ERROR:root:Unable to detect language for text  (1) 2) 3) 4) 5) 6) 7) 8) 9) 10) 11) 12) 13) 14) 15) 16) 17) 18) 19) 20) 21) 22) 23) 24) 25) 26) 27) 28) 29) 30) 31) 32) 33) 34) 35) 36) 37) 38) 39) 40) 41) 42) 43) 44) 45) 46) 47) 48) 49) 50) 51) 52) 53) 54) 55) 56) 57) 58) 59) 60) 61) 62) 63) 64) 65) 66) 67) 68) 69) 70) 71) 72) 73) 74) 75) 76) 77) 78) 79) 80) 81) 82) 83) 84) 85) 86) 87) 88) 89) 90) 91) 92) 93) 94) 95) 96) 97) 98) 99) 100) 101) 102) 103) 104) 105) 106) 107) 108) 109) 110) 111) 112) 113) 114) 115) 116) 117) 118) 119) 120) 121) 122) 123) 124) 125) 126) 127) 128) 129) 130) 131) 132) 133) 134) 135) 136) 137) 138) 139) 140) 141) 142) 143) 144) 145) 146) 147) 148) 149) 150) 151) 152) 153) 154) 155) 156) 157) 158) 159) 160) 161) 162) 163) 164) 165) 166) 167) 168) 169) 170) 171) 172) 173) 174) 175) 176) 177) 178) 179) 180) 181) 182) 183) 184) 185) 186) 187) 188) 189) 190) 191) 192) 193) 194) 195) 196) 197) 198) 199) 200) 201) 202) 203) 204) 205) 206) 207) 208) 209) 210) 211) 212) 213) 214) 215) 216) 217) 218) 219) 220) 221) 222) 223) 224) 225) 226) 227) 228) 229) 230) 231) 232) 233) 234) 235) 236) 237) 238) 239) 240) 241) 242) 243) 244) 245) 246) 247) 248) 249) 250) 251) 252) 253) 254) 255) 256) 257) 258) 259) 260) 261) 262) 263) 264) 265) 266) 267) 268) 269) 270) 271) 272) 273) 274) 275) 276) 277) 278) 279) 280) 281) 282) 283) 284) 285) 286) 287) 288) 289) 290) 291) 292) 293) 294) 295) 296) 297) 298) 299) 300) 301) 302) 303) 304) 305) 306) 307) 308) 309) 310) 311) 312) 313) 314) 315) 316) 317) 318) 319) 320) 321) 322) 323) 324) 325) 326) 327) 328) 329) 330) 331) 332) 333) 334) 335) 336) 337) 338) 339) 340) 341) 342) 343) 344) 345) 346) 347) 348) 349) 350) 351) 352) 353) 354) 355) 356) 357) 358) 359) 360) 361) 362) 363) 364) 365) 366) 367) 368) 369) 370) 371) 372) 373) 374) 375) 376) 377) 378) 379) 380) 381) 382) 383) 384) 385) 386) 387) 388) 389) 390) 391) 392) 393) 394) 395) 396) 397) 398) 399) 400) 401) 402) 403) 404) 405) 406) 407) 408) 409) 410) 411) 412) 413) 414) 415) 416) 417) 418) 419) 420) 421) 422) 423) 424) 425) 426) 427 due to No features in text.
ERROR:root:Unable to detect language for text  (1) 2) 3) 4) 5) 6) 7) 8) 9) 10) 11) 12) 13) 14) 15) 16) 17) 18) 19) 20) 21) 22) 23) 24) 25) 26) 27) 28) 29) 30) 31) 32) 33) 34) 35) 36) 37) 38) 39) 40) 41) 42) 43) 44) 45) 46) 47) 48) 49) 50) 51) 52) 53) 54) 55) 56) 57) 58) 59) 60) 61) 62) 63) 64) 65) 66) 67) 68) 69) 70) 71) 72) 73) 74) 75) 76) 77) 78) 79) 80) 81) 82) 83) 84) 85) 86) 87) 88) 89) 90) 91) 92) 93) 94) 95) 96) 97) 98) 99) 100) 101) 102) 103) 104) 105) 106) 107) 108) 109) 110) 111) 112) 113) 114) 115) 116) 117) 118) 119) 120) 121) 122) 123) 124) 125) 126) 127) 128) 129) 130) 131) 132) 133) 134) 135) 136) 137) 138) 139) 140) 141) 142) 143) 144) 145) 146) 147) 148) 149) 150) 151) 152) 153) 154) 155) 156) 157) 158) 159) 160) 161) 162) 163) 164) 165) 166) 167) 168) 169) 170) 171) 172) 173) 174) 175) 176) 177) 178) 179) 180) 181) 182) 183) 184) 185) 186) 187) 188) 189) 190) 191) 192) 193) 194) 195) 196) 197) 198) 199) 200) 201) 202) 203) 204) 205) 206) 207) 208) 209) 210) 211) 212) 213) 214) 215) 216) 217) 218) 219) 220) 221) 222) 223) 224) 225) 226) 227) 228) 229) 230) 231) 232) 233) 234) 235) 236) 237) 238) 239) 240) 241) 242) 243) 244) 245) 246) 247) 248) 249) 250) 251) 252) 253) 254) 255) 256) 257) 258) 259) 260) 261) 262) 263) 264) 265) 266) 267) 268) 269) 270) 271) 272) 273) 274) 275) 276) 277) 278) 279) 280) 281) 282) 283) 284) 285) 286) 287) 288) 289) 290) 291) 292) 293) 294) 295) 296) 297) 298) 299) 300) 301) 302) 303) 304) 305) 306) 307) 308) 309) 310) 311) 312) 313) 314) 315) 316) 317) 318) 319) 320) 321) 322) 323) 324) 325) 326) 327) 328) 329) 330) 331) 332) 333) 334) 335) 336) 337) 338) 339) 340) 341) 342) 343) 344) 345) 346) 347) 348) 349) 350) 351) 352) 353) 354) 355) 356) 357) 358) 359) 360) 361) 362) 363) 364) 365) 366) 367) 368) 369) 370) 371) 372) 373) 374) 375) 376) 377) 378) 379) 380) 381) 382) 383) 384) 385) 386) 387) 388) 389) 390) 391) 392) 393) 394) 395) 396) 397) 398) 399) 400) 401) 402) 403) 404) 405) 406) 407) 408) 409) 410) 411) 412) 413) 414) 415) 416) 417) 418) 419) 420) 421) 422) 423) 424) 425) 426) 427 due to No features in text.
INFO:lm_eval.loggers.evaluation_tracker:Saving results aggregated
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: ifeval
hf (pretrained=meta-llama/Llama-3.2-1B-Instruct), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 128
|Tasks |Version|Filter|n-shot|        Metric         |   |Value |   |Stderr|
|------|------:|------|-----:|-----------------------|---|-----:|---|------|
|ifeval|      4|none  |     0|inst_level_loose_acc   |↑  |0.5516|±  |   N/A|
|      |       |none  |     0|inst_level_strict_acc  |↑  |0.5096|±  |   N/A|
|      |       |none  |     0|prompt_level_loose_acc |↑  |0.4067|±  |0.0211|
|      |       |none  |     0|prompt_level_strict_acc|↑  |0.3641|±  |0.0207|

