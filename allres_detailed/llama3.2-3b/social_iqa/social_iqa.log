INFO 04-10 07:18:52 [__init__.py:239] Automatically detected platform cuda.
INFO:lm_eval.__main__:Selected Tasks: ['social_iqa']
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO:lm_eval.models.huggingface:Using device 'cuda'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of social_iqa from None to 0
INFO:lm_eval.api.task:Building contexts for social_iqa on rank 0...
  0%|          | 0/1954 [00:00<?, ?it/s]  9%|▉         | 174/1954 [00:00<00:01, 1731.70it/s] 18%|█▊        | 348/1954 [00:00<00:00, 1734.65it/s] 27%|██▋       | 522/1954 [00:00<00:00, 1732.19it/s] 36%|███▌      | 698/1954 [00:00<00:00, 1741.55it/s] 45%|████▍     | 874/1954 [00:00<00:00, 1746.15it/s] 54%|█████▎    | 1049/1954 [00:00<00:00, 1733.70it/s] 63%|██████▎   | 1225/1954 [00:00<00:00, 1742.15it/s] 72%|███████▏  | 1400/1954 [00:00<00:00, 1741.52it/s] 81%|████████  | 1576/1954 [00:00<00:00, 1746.33it/s] 90%|████████▉ | 1753/1954 [00:01<00:00, 1751.78it/s] 99%|█████████▉| 1930/1954 [00:01<00:00, 1755.94it/s]100%|██████████| 1954/1954 [00:01<00:00, 1745.52it/s]
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/5862 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/5862 [00:00<1:06:12,  1.48it/s]Running loglikelihood requests:   2%|▏         | 133/5862 [00:00<00:25, 226.16it/s]Running loglikelihood requests:   5%|▍         | 266/5862 [00:00<00:12, 436.99it/s]Running loglikelihood requests:   7%|▋         | 404/5862 [00:00<00:08, 640.71it/s]Running loglikelihood requests:   9%|▉         | 541/5862 [00:01<00:06, 812.85it/s]Running loglikelihood requests:  12%|█▏        | 704/5862 [00:01<00:05, 1018.90it/s]Running loglikelihood requests:  15%|█▌        | 888/5862 [00:01<00:04, 1236.38it/s]Running loglikelihood requests:  18%|█▊        | 1069/5862 [00:01<00:04, 1154.18it/s]Running loglikelihood requests:  22%|██▏       | 1300/5862 [00:01<00:03, 1437.39it/s]Running loglikelihood requests:  25%|██▌       | 1478/5862 [00:01<00:03, 1291.94it/s]Running loglikelihood requests:  29%|██▉       | 1720/5862 [00:01<00:02, 1561.04it/s]Running loglikelihood requests:  32%|███▏      | 1896/5862 [00:02<00:02, 1388.75it/s]Running loglikelihood requests:  37%|███▋      | 2156/5862 [00:02<00:02, 1436.28it/s]Running loglikelihood requests:  41%|████▏     | 2425/5862 [00:02<00:02, 1485.90it/s]Running loglikelihood requests:  46%|████▌     | 2698/5862 [00:02<00:02, 1548.29it/s]Running loglikelihood requests:  51%|█████     | 2974/5862 [00:02<00:01, 1599.24it/s]Running loglikelihood requests:  56%|█████▌    | 3254/5862 [00:02<00:01, 1646.10it/s]Running loglikelihood requests:  60%|██████    | 3536/5862 [00:02<00:01, 1678.84it/s]Running loglikelihood requests:  65%|██████▌   | 3812/5862 [00:03<00:01, 1708.29it/s]Running loglikelihood requests:  70%|██████▉   | 4086/5862 [00:03<00:01, 1735.00it/s]Running loglikelihood requests:  75%|███████▍  | 4376/5862 [00:03<00:00, 1778.64it/s]Running loglikelihood requests:  80%|███████▉  | 4666/5862 [00:03<00:00, 1825.27it/s]Running loglikelihood requests:  85%|████████▍ | 4961/5862 [00:03<00:00, 1871.18it/s]Running loglikelihood requests:  90%|████████▉ | 5271/5862 [00:03<00:00, 1952.10it/s]Running loglikelihood requests:  95%|█████████▌| 5578/5862 [00:04<00:00, 2013.24it/s]Running loglikelihood requests: 100%|██████████| 5862/5862 [00:04<00:00, 1430.99it/s]
INFO:lm_eval.loggers.evaluation_tracker:Saving results aggregated
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: social_iqa
hf (pretrained=meta-llama/Llama-3.2-3B-Instruct), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 128
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|social_iqa|      0|none  |     0|acc   |↑  |0.4509|±  |0.0113|

