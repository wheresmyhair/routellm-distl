INFO 04-10 06:17:48 [__init__.py:239] Automatically detected platform cuda.
INFO:lm_eval.__main__:Selected Tasks: ['mmlu']
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.2-1B-Instruct'}
INFO:lm_eval.models.huggingface:Using device 'cuda'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_anatomy from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_astronomy from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_college_biology from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_college_physics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_computer_security from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_machine_learning from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_business_ethics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_college_medicine from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_global_facts from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_human_aging from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_management from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_marketing from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_nutrition from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_virology from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_econometrics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_public_relations from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_security_studies from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_sociology from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_formal_logic from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_international_law from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_philosophy from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_prehistory from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_professional_law from None to 0
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mmlu_world_religions from None to 0
INFO:lm_eval.api.task:Building contexts for mmlu_abstract_algebra on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1153.16it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_anatomy on rank 0...
  0%|          | 0/135 [00:00<?, ?it/s] 86%|████████▌ | 116/135 [00:00<00:00, 1152.78it/s]100%|██████████| 135/135 [00:00<00:00, 1151.77it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_astronomy on rank 0...
  0%|          | 0/152 [00:00<?, ?it/s] 77%|███████▋  | 117/152 [00:00<00:00, 1164.06it/s]100%|██████████| 152/152 [00:00<00:00, 1163.24it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_college_biology on rank 0...
  0%|          | 0/144 [00:00<?, ?it/s] 81%|████████▏ | 117/144 [00:00<00:00, 1160.79it/s]100%|██████████| 144/144 [00:00<00:00, 1165.25it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_college_chemistry on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1173.59it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_college_computer_science on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1172.47it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_college_mathematics on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1170.35it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_college_physics on rank 0...
  0%|          | 0/102 [00:00<?, ?it/s]100%|██████████| 102/102 [00:00<00:00, 1160.62it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_computer_security on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1170.15it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_conceptual_physics on rank 0...
  0%|          | 0/235 [00:00<?, ?it/s] 50%|████▉     | 117/235 [00:00<00:00, 1169.38it/s]100%|██████████| 235/235 [00:00<00:00, 1172.44it/s]100%|██████████| 235/235 [00:00<00:00, 1171.30it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_electrical_engineering on rank 0...
  0%|          | 0/145 [00:00<?, ?it/s] 81%|████████▏ | 118/145 [00:00<00:00, 1179.10it/s]100%|██████████| 145/145 [00:00<00:00, 1178.10it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_elementary_mathematics on rank 0...
  0%|          | 0/378 [00:00<?, ?it/s] 31%|███       | 118/378 [00:00<00:00, 1170.68it/s] 63%|██████▎   | 237/378 [00:00<00:00, 1179.49it/s] 94%|█████████▍| 355/378 [00:00<00:00, 569.58it/s] 100%|██████████| 378/378 [00:00<00:00, 678.85it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_biology on rank 0...
  0%|          | 0/310 [00:00<?, ?it/s] 38%|███▊      | 117/310 [00:00<00:00, 1160.61it/s] 75%|███████▌  | 234/310 [00:00<00:00, 1134.08it/s]100%|██████████| 310/310 [00:00<00:00, 1144.47it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_chemistry on rank 0...
  0%|          | 0/203 [00:00<?, ?it/s] 57%|█████▋    | 116/203 [00:00<00:00, 1152.25it/s]100%|██████████| 203/203 [00:00<00:00, 1152.32it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_computer_science on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1157.64it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_mathematics on rank 0...
  0%|          | 0/270 [00:00<?, ?it/s] 44%|████▍     | 119/270 [00:00<00:00, 1182.55it/s] 88%|████████▊ | 238/270 [00:00<00:00, 1178.74it/s]100%|██████████| 270/270 [00:00<00:00, 1178.24it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_physics on rank 0...
  0%|          | 0/151 [00:00<?, ?it/s] 78%|███████▊  | 118/151 [00:00<00:00, 1173.82it/s]100%|██████████| 151/151 [00:00<00:00, 1174.49it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_statistics on rank 0...
  0%|          | 0/216 [00:00<?, ?it/s] 55%|█████▍    | 118/216 [00:00<00:00, 1177.00it/s]100%|██████████| 216/216 [00:00<00:00, 1179.10it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_machine_learning on rank 0...
  0%|          | 0/112 [00:00<?, ?it/s]100%|██████████| 112/112 [00:00<00:00, 1129.33it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_business_ethics on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1173.05it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_clinical_knowledge on rank 0...
  0%|          | 0/265 [00:00<?, ?it/s] 45%|████▍     | 119/265 [00:00<00:00, 1184.73it/s] 90%|████████▉ | 238/265 [00:00<00:00, 1174.14it/s]100%|██████████| 265/265 [00:00<00:00, 1175.05it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_college_medicine on rank 0...
  0%|          | 0/173 [00:00<?, ?it/s] 68%|██████▊   | 118/173 [00:00<00:00, 1172.25it/s]100%|██████████| 173/173 [00:00<00:00, 1173.19it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_global_facts on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1169.40it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_human_aging on rank 0...
  0%|          | 0/223 [00:00<?, ?it/s] 50%|████▉     | 111/223 [00:00<00:00, 1106.24it/s]100%|██████████| 223/223 [00:00<00:00, 1133.18it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_management on rank 0...
  0%|          | 0/103 [00:00<?, ?it/s]100%|██████████| 103/103 [00:00<00:00, 1173.28it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_marketing on rank 0...
  0%|          | 0/234 [00:00<?, ?it/s] 51%|█████     | 119/234 [00:00<00:00, 1179.50it/s]100%|██████████| 234/234 [00:00<00:00, 1180.51it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_medical_genetics on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1172.41it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_miscellaneous on rank 0...
  0%|          | 0/783 [00:00<?, ?it/s] 15%|█▌        | 119/783 [00:00<00:00, 1185.28it/s] 30%|███       | 238/783 [00:00<00:00, 1186.24it/s] 46%|████▌     | 357/783 [00:00<00:00, 1184.53it/s] 61%|██████    | 476/783 [00:00<00:00, 1184.22it/s] 76%|███████▌  | 595/783 [00:00<00:00, 1181.60it/s] 91%|█████████ | 714/783 [00:00<00:00, 1180.92it/s]100%|██████████| 783/783 [00:00<00:00, 1182.31it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_nutrition on rank 0...
  0%|          | 0/306 [00:00<?, ?it/s] 29%|██▉       | 88/306 [00:00<00:00, 269.10it/s] 67%|██████▋   | 204/306 [00:00<00:00, 539.09it/s]100%|██████████| 306/306 [00:00<00:00, 593.91it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_professional_accounting on rank 0...
  0%|          | 0/282 [00:00<?, ?it/s] 42%|████▏     | 118/282 [00:00<00:00, 1178.48it/s] 84%|████████▎ | 236/282 [00:00<00:00, 1165.97it/s]100%|██████████| 282/282 [00:00<00:00, 1169.38it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_professional_medicine on rank 0...
  0%|          | 0/272 [00:00<?, ?it/s] 43%|████▎     | 117/272 [00:00<00:00, 1169.00it/s] 87%|████████▋ | 236/272 [00:00<00:00, 1177.55it/s]100%|██████████| 272/272 [00:00<00:00, 1175.74it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_virology on rank 0...
  0%|          | 0/166 [00:00<?, ?it/s] 70%|███████   | 117/166 [00:00<00:00, 1167.42it/s]100%|██████████| 166/166 [00:00<00:00, 1169.12it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_econometrics on rank 0...
  0%|          | 0/114 [00:00<?, ?it/s]100%|██████████| 114/114 [00:00<00:00, 1169.78it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_geography on rank 0...
  0%|          | 0/198 [00:00<?, ?it/s] 60%|██████    | 119/198 [00:00<00:00, 1181.10it/s]100%|██████████| 198/198 [00:00<00:00, 1175.78it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_government_and_politics on rank 0...
  0%|          | 0/193 [00:00<?, ?it/s] 61%|██████    | 118/193 [00:00<00:00, 1172.56it/s]100%|██████████| 193/193 [00:00<00:00, 1172.03it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_macroeconomics on rank 0...
  0%|          | 0/390 [00:00<?, ?it/s] 30%|███       | 118/390 [00:00<00:00, 1175.52it/s] 61%|██████    | 236/390 [00:00<00:00, 1175.44it/s] 91%|█████████ | 355/390 [00:00<00:00, 1179.22it/s]100%|██████████| 390/390 [00:00<00:00, 1178.33it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_microeconomics on rank 0...
  0%|          | 0/238 [00:00<?, ?it/s] 50%|████▉     | 118/238 [00:00<00:00, 1174.27it/s] 99%|█████████▉| 236/238 [00:00<00:00, 1160.64it/s]100%|██████████| 238/238 [00:00<00:00, 1162.00it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_psychology on rank 0...
  0%|          | 0/545 [00:00<?, ?it/s] 22%|██▏       | 118/545 [00:00<00:00, 1176.26it/s] 43%|████▎     | 236/545 [00:00<00:00, 1174.49it/s] 65%|██████▌   | 355/545 [00:00<00:00, 1177.61it/s] 87%|████████▋ | 473/545 [00:00<00:00, 1177.83it/s]100%|██████████| 545/545 [00:00<00:00, 1177.76it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_human_sexuality on rank 0...
  0%|          | 0/131 [00:00<?, ?it/s] 90%|█████████ | 118/131 [00:00<00:00, 1170.89it/s]100%|██████████| 131/131 [00:00<00:00, 1169.51it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_professional_psychology on rank 0...
  0%|          | 0/612 [00:00<?, ?it/s] 19%|█▉        | 118/612 [00:00<00:00, 1171.64it/s] 39%|███▊      | 237/612 [00:00<00:00, 1178.02it/s] 58%|█████▊    | 355/612 [00:00<00:00, 1177.53it/s] 77%|███████▋  | 474/612 [00:00<00:00, 1179.50it/s] 97%|█████████▋| 592/612 [00:00<00:00, 1176.14it/s]100%|██████████| 612/612 [00:00<00:00, 1176.33it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_public_relations on rank 0...
  0%|          | 0/110 [00:00<?, ?it/s]100%|██████████| 110/110 [00:00<00:00, 1180.54it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_security_studies on rank 0...
  0%|          | 0/245 [00:00<?, ?it/s] 48%|████▊     | 118/245 [00:00<00:00, 1174.81it/s] 97%|█████████▋| 237/245 [00:00<00:00, 1178.69it/s]100%|██████████| 245/245 [00:00<00:00, 1177.01it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_sociology on rank 0...
  0%|          | 0/201 [00:00<?, ?it/s] 44%|████▍     | 89/201 [00:00<00:00, 259.73it/s]100%|██████████| 201/201 [00:00<00:00, 457.15it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_us_foreign_policy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1164.25it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_formal_logic on rank 0...
  0%|          | 0/126 [00:00<?, ?it/s] 93%|█████████▎| 117/126 [00:00<00:00, 1165.47it/s]100%|██████████| 126/126 [00:00<00:00, 1164.41it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_european_history on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 72%|███████▏  | 118/165 [00:00<00:00, 1174.35it/s]100%|██████████| 165/165 [00:00<00:00, 1176.46it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_us_history on rank 0...
  0%|          | 0/204 [00:00<?, ?it/s] 58%|█████▊    | 118/204 [00:00<00:00, 1179.17it/s]100%|██████████| 204/204 [00:00<00:00, 1180.02it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_high_school_world_history on rank 0...
  0%|          | 0/237 [00:00<?, ?it/s] 49%|████▉     | 116/237 [00:00<00:00, 1155.58it/s] 99%|█████████▊| 234/237 [00:00<00:00, 1164.08it/s]100%|██████████| 237/237 [00:00<00:00, 1162.20it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_international_law on rank 0...
  0%|          | 0/121 [00:00<?, ?it/s] 96%|█████████▌| 116/121 [00:00<00:00, 1150.98it/s]100%|██████████| 121/121 [00:00<00:00, 1149.31it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_jurisprudence on rank 0...
  0%|          | 0/108 [00:00<?, ?it/s]100%|██████████| 108/108 [00:00<00:00, 1157.17it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_logical_fallacies on rank 0...
  0%|          | 0/163 [00:00<?, ?it/s] 71%|███████   | 116/163 [00:00<00:00, 1159.94it/s]100%|██████████| 163/163 [00:00<00:00, 1162.01it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_moral_disputes on rank 0...
  0%|          | 0/346 [00:00<?, ?it/s] 34%|███▍      | 117/346 [00:00<00:00, 1164.06it/s] 68%|██████▊   | 234/346 [00:00<00:00, 1164.53it/s]100%|██████████| 346/346 [00:00<00:00, 1168.55it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_moral_scenarios on rank 0...
  0%|          | 0/895 [00:00<?, ?it/s] 13%|█▎        | 118/895 [00:00<00:00, 1172.86it/s] 26%|██▋       | 236/895 [00:00<00:00, 1173.31it/s] 40%|███▉      | 354/895 [00:00<00:00, 1172.79it/s] 53%|█████▎    | 472/895 [00:00<00:00, 1173.19it/s] 66%|██████▌   | 590/895 [00:00<00:00, 1173.49it/s] 79%|███████▉  | 708/895 [00:00<00:00, 1175.46it/s] 92%|█████████▏| 826/895 [00:00<00:00, 1170.64it/s]100%|██████████| 895/895 [00:00<00:00, 1172.00it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_philosophy on rank 0...
  0%|          | 0/311 [00:00<?, ?it/s] 38%|███▊      | 117/311 [00:00<00:00, 1169.03it/s] 76%|███████▌  | 236/311 [00:00<00:00, 1175.58it/s]100%|██████████| 311/311 [00:00<00:00, 1174.50it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_prehistory on rank 0...
  0%|          | 0/324 [00:00<?, ?it/s] 36%|███▋      | 118/324 [00:00<00:00, 1177.85it/s] 73%|███████▎  | 236/324 [00:00<00:00, 1178.20it/s]100%|██████████| 324/324 [00:00<00:00, 1178.28it/s]
INFO:lm_eval.api.task:Building contexts for mmlu_professional_law on rank 0...
  0%|          | 0/1534 [00:00<?, ?it/s]  8%|▊         | 118/1534 [00:00<00:01, 1171.41it/s] 15%|█▌        | 236/1534 [00:00<00:01, 1175.23it/s] 23%|██▎       | 354/1534 [00:00<00:01, 1173.99it/s] 31%|███       | 472/1534 [00:00<00:00, 1174.87it/s] 38%|███▊      | 590/1534 [00:00<00:01, 592.43it/s]  46%|████▌     | 706/1534 [00:00<00:01, 708.39it/s] 54%|█████▎    | 822/1534 [00:00<00:00, 810.66it/s] 61%|██████    | 939/1534 [00:01<00:00, 897.00it/s] 69%|██████▉   | 1056/1534 [00:01<00:00, 966.49it/s] 76%|███████▋  | 1173/1534 [00:01<00:00, 1020.23it/s] 84%|████████▍ | 1290/1534 [00:01<00:00, 1060.60it/s] 92%|█████████▏| 1407/1534 [00:01<00:00, 1090.31it/s] 99%|█████████▉| 1524/1534 [00:01<00:00, 1112.09it/s]100%|██████████| 1534/1534 [00:01<00:00, 965.87it/s] 
INFO:lm_eval.api.task:Building contexts for mmlu_world_religions on rank 0...
  0%|          | 0/171 [00:00<?, ?it/s] 67%|██████▋   | 115/171 [00:00<00:00, 1140.03it/s]100%|██████████| 171/171 [00:00<00:00, 1148.47it/s]
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/56168 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/56168 [00:03<53:39:03,  3.44s/it]Running loglikelihood requests:   0%|          | 257/56168 [00:03<09:40, 96.30it/s] Running loglikelihood requests:   1%|          | 513/56168 [00:03<04:26, 208.56it/s]Running loglikelihood requests:   1%|▏         | 769/56168 [00:04<02:45, 335.52it/s]Running loglikelihood requests:   2%|▏         | 1025/56168 [00:04<01:56, 474.51it/s]Running loglikelihood requests:   2%|▏         | 1281/56168 [00:04<01:28, 618.91it/s]Running loglikelihood requests:   3%|▎         | 1537/56168 [00:04<01:11, 767.83it/s]Running loglikelihood requests:   3%|▎         | 1793/56168 [00:04<00:59, 913.42it/s]Running loglikelihood requests:   4%|▎         | 2049/56168 [00:05<00:51, 1048.93it/s]Running loglikelihood requests:   4%|▍         | 2305/56168 [00:05<00:46, 1168.40it/s]Running loglikelihood requests:   5%|▍         | 2561/56168 [00:05<00:42, 1272.07it/s]Running loglikelihood requests:   5%|▌         | 2817/56168 [00:05<00:39, 1367.55it/s]Running loglikelihood requests:   5%|▌         | 3073/56168 [00:05<00:36, 1449.03it/s]Running loglikelihood requests:   6%|▌         | 3329/56168 [00:05<00:34, 1513.83it/s]Running loglikelihood requests:   6%|▋         | 3585/56168 [00:05<00:33, 1574.93it/s]Running loglikelihood requests:   7%|▋         | 3841/56168 [00:06<00:32, 1629.21it/s]Running loglikelihood requests:   7%|▋         | 4097/56168 [00:06<00:31, 1677.79it/s]Running loglikelihood requests:   8%|▊         | 4353/56168 [00:06<00:30, 1722.66it/s]Running loglikelihood requests:   8%|▊         | 4609/56168 [00:06<00:29, 1764.18it/s]Running loglikelihood requests:   9%|▊         | 4865/56168 [00:06<00:28, 1795.26it/s]Running loglikelihood requests:   9%|▉         | 5121/56168 [00:06<00:27, 1838.44it/s]Running loglikelihood requests:  10%|▉         | 5377/56168 [00:06<00:26, 1890.70it/s]Running loglikelihood requests:  10%|█         | 5633/56168 [00:07<00:26, 1939.79it/s]Running loglikelihood requests:  10%|█         | 5889/56168 [00:07<00:25, 1989.88it/s]Running loglikelihood requests:  11%|█         | 6145/56168 [00:07<00:24, 2035.37it/s]Running loglikelihood requests:  11%|█▏        | 6401/56168 [00:07<00:23, 2080.19it/s]Running loglikelihood requests:  12%|█▏        | 6657/56168 [00:07<00:23, 2117.95it/s]Running loglikelihood requests:  12%|█▏        | 6913/56168 [00:07<00:22, 2152.22it/s]Running loglikelihood requests:  13%|█▎        | 7169/56168 [00:07<00:22, 2182.49it/s]Running loglikelihood requests:  13%|█▎        | 7425/56168 [00:07<00:21, 2219.44it/s]Running loglikelihood requests:  14%|█▎        | 7681/56168 [00:07<00:21, 2267.54it/s]Running loglikelihood requests:  14%|█▍        | 7937/56168 [00:08<00:20, 2303.61it/s]Running loglikelihood requests:  15%|█▍        | 8193/56168 [00:08<00:20, 2349.28it/s]Running loglikelihood requests:  15%|█▌        | 8449/56168 [00:08<00:20, 2383.08it/s]Running loglikelihood requests:  15%|█▌        | 8705/56168 [00:08<00:19, 2431.94it/s]Running loglikelihood requests:  16%|█▌        | 8984/56168 [00:08<00:18, 2535.27it/s]Running loglikelihood requests:  17%|█▋        | 9288/56168 [00:08<00:17, 2682.51it/s]Running loglikelihood requests:  17%|█▋        | 9627/56168 [00:08<00:16, 2890.75it/s]Running loglikelihood requests:  18%|█▊        | 9973/56168 [00:08<00:15, 3058.97it/s]Running loglikelihood requests:  18%|█▊        | 10280/56168 [00:08<00:18, 2546.51it/s]Running loglikelihood requests:  19%|█▉        | 10702/56168 [00:09<00:15, 2983.30it/s]Running loglikelihood requests:  20%|█▉        | 11018/56168 [00:09<00:17, 2609.97it/s]Running loglikelihood requests:  20%|██        | 11489/56168 [00:09<00:14, 3135.30it/s]Running loglikelihood requests:  21%|██        | 11827/56168 [00:09<00:15, 2812.76it/s]Running loglikelihood requests:  22%|██▏       | 12293/56168 [00:09<00:15, 2861.30it/s]Running loglikelihood requests:  23%|██▎       | 12805/56168 [00:09<00:14, 2993.97it/s]Running loglikelihood requests:  24%|██▎       | 13317/56168 [00:09<00:13, 3089.77it/s]Running loglikelihood requests:  25%|██▍       | 13829/56168 [00:10<00:13, 3196.37it/s]Running loglikelihood requests:  26%|██▌       | 14341/56168 [00:10<00:12, 3287.77it/s]Running loglikelihood requests:  26%|██▋       | 14853/56168 [00:10<00:12, 3363.96it/s]Running loglikelihood requests:  27%|██▋       | 15365/56168 [00:10<00:11, 3414.22it/s]Running loglikelihood requests:  28%|██▊       | 15877/56168 [00:10<00:11, 3489.51it/s]Running loglikelihood requests:  29%|██▉       | 16393/56168 [00:10<00:11, 3555.57it/s]Running loglikelihood requests:  30%|███       | 16905/56168 [00:10<00:10, 3605.06it/s]Running loglikelihood requests:  31%|███       | 17417/56168 [00:11<00:10, 3638.95it/s]Running loglikelihood requests:  32%|███▏      | 17929/56168 [00:11<00:10, 3662.40it/s]Running loglikelihood requests:  33%|███▎      | 18441/56168 [00:11<00:10, 3680.19it/s]Running loglikelihood requests:  34%|███▍      | 18957/56168 [00:11<00:09, 3726.61it/s]Running loglikelihood requests:  35%|███▍      | 19469/56168 [00:11<00:09, 3757.02it/s]Running loglikelihood requests:  36%|███▌      | 19981/56168 [00:11<00:09, 3783.94it/s]Running loglikelihood requests:  36%|███▋      | 20497/56168 [00:11<00:09, 3809.26it/s]Running loglikelihood requests:  37%|███▋      | 21013/56168 [00:12<00:09, 3845.30it/s]Running loglikelihood requests:  38%|███▊      | 21529/56168 [00:12<00:08, 3887.59it/s]Running loglikelihood requests:  39%|███▉      | 22041/56168 [00:12<00:08, 3938.26it/s]Running loglikelihood requests:  40%|████      | 22553/56168 [00:12<00:08, 3962.69it/s]Running loglikelihood requests:  41%|████      | 23073/56168 [00:12<00:08, 4019.16it/s]Running loglikelihood requests:  42%|████▏     | 23585/56168 [00:12<00:08, 4045.54it/s]Running loglikelihood requests:  43%|████▎     | 24097/56168 [00:12<00:07, 4079.28it/s]Running loglikelihood requests:  44%|████▍     | 24609/56168 [00:12<00:07, 4115.71it/s]Running loglikelihood requests:  45%|████▍     | 25125/56168 [00:13<00:07, 4157.24it/s]Running loglikelihood requests:  46%|████▌     | 25637/56168 [00:13<00:07, 4177.80it/s]Running loglikelihood requests:  47%|████▋     | 26149/56168 [00:13<00:07, 4209.60it/s]Running loglikelihood requests:  47%|████▋     | 26661/56168 [00:13<00:06, 4244.23it/s]Running loglikelihood requests:  48%|████▊     | 27173/56168 [00:13<00:06, 4283.74it/s]Running loglikelihood requests:  49%|████▉     | 27685/56168 [00:13<00:06, 4312.25it/s]Running loglikelihood requests:  50%|█████     | 28205/56168 [00:13<00:06, 4373.42it/s]Running loglikelihood requests:  51%|█████     | 28717/56168 [00:13<00:06, 4405.03it/s]Running loglikelihood requests:  52%|█████▏    | 29229/56168 [00:13<00:06, 4440.62it/s]Running loglikelihood requests:  53%|█████▎    | 29745/56168 [00:14<00:05, 4480.27it/s]Running loglikelihood requests:  54%|█████▍    | 30257/56168 [00:14<00:05, 4504.46it/s]Running loglikelihood requests:  55%|█████▍    | 30769/56168 [00:14<00:05, 4519.60it/s]Running loglikelihood requests:  56%|█████▌    | 31281/56168 [00:14<00:05, 4560.31it/s]Running loglikelihood requests:  57%|█████▋    | 31797/56168 [00:14<00:05, 4603.52it/s]Running loglikelihood requests:  58%|█████▊    | 32313/56168 [00:14<00:05, 4640.11it/s]Running loglikelihood requests:  58%|█████▊    | 32825/56168 [00:14<00:05, 4662.77it/s]Running loglikelihood requests:  59%|█████▉    | 33337/56168 [00:14<00:04, 4703.62it/s]Running loglikelihood requests:  60%|██████    | 33849/56168 [00:14<00:04, 4737.15it/s]Running loglikelihood requests:  61%|██████    | 34365/56168 [00:15<00:04, 4785.56it/s]Running loglikelihood requests:  62%|██████▏   | 34877/56168 [00:15<00:04, 4805.84it/s]Running loglikelihood requests:  63%|██████▎   | 35389/56168 [00:15<00:04, 4820.83it/s]Running loglikelihood requests:  64%|██████▍   | 35901/56168 [00:15<00:04, 4871.08it/s]Running loglikelihood requests:  65%|██████▍   | 36417/56168 [00:15<00:04, 4920.93it/s]Running loglikelihood requests:  66%|██████▌   | 36933/56168 [00:15<00:03, 4972.26it/s]Running loglikelihood requests:  67%|██████▋   | 37445/56168 [00:15<00:03, 4997.04it/s]Running loglikelihood requests:  68%|██████▊   | 37961/56168 [00:15<00:03, 5043.42it/s]Running loglikelihood requests:  69%|██████▊   | 38485/56168 [00:15<00:03, 5100.38it/s]Running loglikelihood requests:  69%|██████▉   | 39015/56168 [00:15<00:03, 5159.61it/s]Running loglikelihood requests:  70%|███████   | 39546/56168 [00:16<00:03, 5204.03it/s]Running loglikelihood requests:  71%|███████▏  | 40070/56168 [00:16<00:03, 5214.36it/s]Running loglikelihood requests:  72%|███████▏  | 40598/56168 [00:16<00:02, 5233.18it/s]Running loglikelihood requests:  73%|███████▎  | 41189/56168 [00:16<00:02, 5434.52it/s]Running loglikelihood requests:  74%|███████▍  | 41778/56168 [00:16<00:02, 5570.35it/s]Running loglikelihood requests:  75%|███████▌  | 42336/56168 [00:16<00:02, 5154.29it/s]Running loglikelihood requests:  76%|███████▋  | 42932/56168 [00:16<00:02, 5382.51it/s]Running loglikelihood requests:  78%|███████▊  | 43549/56168 [00:16<00:02, 5609.00it/s]Running loglikelihood requests:  79%|███████▊  | 44121/56168 [00:16<00:02, 5257.29it/s]Running loglikelihood requests:  80%|███████▉  | 44769/56168 [00:17<00:02, 5598.68it/s]Running loglikelihood requests:  81%|████████  | 45405/56168 [00:17<00:01, 5404.33it/s]Running loglikelihood requests:  82%|████████▏ | 46069/56168 [00:17<00:01, 5742.94it/s]Running loglikelihood requests:  83%|████████▎ | 46689/56168 [00:17<00:01, 5487.69it/s]Running loglikelihood requests:  84%|████████▍ | 47364/56168 [00:17<00:01, 5832.12it/s]Running loglikelihood requests:  85%|████████▌ | 47969/56168 [00:17<00:01, 5555.35it/s]Running loglikelihood requests:  87%|████████▋ | 48671/56168 [00:17<00:01, 5957.16it/s]Running loglikelihood requests:  88%|████████▊ | 49277/56168 [00:17<00:01, 5664.73it/s]Running loglikelihood requests:  89%|████████▉ | 49983/56168 [00:17<00:01, 6048.85it/s]Running loglikelihood requests:  90%|█████████ | 50598/56168 [00:18<00:00, 5770.33it/s]Running loglikelihood requests:  91%|█████████▏| 51301/56168 [00:18<00:00, 5752.42it/s]Running loglikelihood requests:  93%|█████████▎| 52045/56168 [00:18<00:00, 6208.95it/s]Running loglikelihood requests:  94%|█████████▍| 52675/56168 [00:18<00:00, 5949.04it/s]Running loglikelihood requests:  95%|█████████▍| 53357/56168 [00:18<00:00, 5886.14it/s]Running loglikelihood requests:  96%|█████████▋| 54121/56168 [00:18<00:00, 6363.59it/s]Running loglikelihood requests:  98%|█████████▊| 54766/56168 [00:18<00:00, 6154.08it/s]Running loglikelihood requests:  99%|█████████▊| 55405/56168 [00:18<00:00, 6020.39it/s]Running loglikelihood requests: 100%|██████████| 56168/56168 [00:18<00:00, 2972.04it/s]
INFO:lm_eval.loggers.evaluation_tracker:Saving results aggregated
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_abstract_algebra
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_anatomy
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_astronomy
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_business_ethics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_clinical_knowledge
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_college_biology
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_college_chemistry
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_college_computer_science
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_college_mathematics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_college_medicine
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_college_physics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_computer_security
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_conceptual_physics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_econometrics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_electrical_engineering
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_elementary_mathematics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_formal_logic
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_global_facts
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_biology
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_chemistry
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_computer_science
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_european_history
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_geography
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_government_and_politics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_macroeconomics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_mathematics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_microeconomics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_physics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_psychology
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_statistics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_us_history
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_high_school_world_history
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_human_aging
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_human_sexuality
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_international_law
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_jurisprudence
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_logical_fallacies
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_machine_learning
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_management
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_marketing
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_medical_genetics
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_miscellaneous
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_moral_disputes
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_moral_scenarios
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_nutrition
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_philosophy
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_prehistory
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_professional_accounting
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_professional_law
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_professional_medicine
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_professional_psychology
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_public_relations
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_security_studies
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_sociology
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_us_foreign_policy
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_virology
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: mmlu_world_religions
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=meta-llama/Llama-3.2-1B-Instruct), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: auto (64)
|                 Tasks                 |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|---------------------------------------|------:|------|-----:|------|---|-----:|---|-----:|
|mmlu                                   |      2|none  |      |acc   |↑  |0.4612|±  |0.0041|
| - humanities                          |      2|none  |      |acc   |↑  |0.4397|±  |0.0071|
|  - formal_logic                       |      1|none  |     0|acc   |↑  |0.3254|±  |0.0419|
|  - high_school_european_history       |      1|none  |     0|acc   |↑  |0.6242|±  |0.0378|
|  - high_school_us_history             |      1|none  |     0|acc   |↑  |0.5735|±  |0.0347|
|  - high_school_world_history          |      1|none  |     0|acc   |↑  |0.6498|±  |0.0311|
|  - international_law                  |      1|none  |     0|acc   |↑  |0.5868|±  |0.0450|
|  - jurisprudence                      |      1|none  |     0|acc   |↑  |0.5185|±  |0.0483|
|  - logical_fallacies                  |      1|none  |     0|acc   |↑  |0.4540|±  |0.0391|
|  - moral_disputes                     |      1|none  |     0|acc   |↑  |0.4566|±  |0.0268|
|  - moral_scenarios                    |      1|none  |     0|acc   |↑  |0.3374|±  |0.0158|
|  - philosophy                         |      1|none  |     0|acc   |↑  |0.5145|±  |0.0284|
|  - prehistory                         |      1|none  |     0|acc   |↑  |0.5247|±  |0.0278|
|  - professional_law                   |      1|none  |     0|acc   |↑  |0.3657|±  |0.0123|
|  - world_religions                    |      1|none  |     0|acc   |↑  |0.5965|±  |0.0376|
| - other                               |      2|none  |      |acc   |↑  |0.5211|±  |0.0088|
|  - business_ethics                    |      1|none  |     0|acc   |↑  |0.4200|±  |0.0496|
|  - clinical_knowledge                 |      1|none  |     0|acc   |↑  |0.4830|±  |0.0308|
|  - college_medicine                   |      1|none  |     0|acc   |↑  |0.3757|±  |0.0369|
|  - global_facts                       |      1|none  |     0|acc   |↑  |0.3200|±  |0.0469|
|  - human_aging                        |      1|none  |     0|acc   |↑  |0.5291|±  |0.0335|
|  - management                         |      1|none  |     0|acc   |↑  |0.5340|±  |0.0494|
|  - marketing                          |      1|none  |     0|acc   |↑  |0.6795|±  |0.0306|
|  - medical_genetics                   |      1|none  |     0|acc   |↑  |0.4700|±  |0.0502|
|  - miscellaneous                      |      1|none  |     0|acc   |↑  |0.6054|±  |0.0175|
|  - nutrition                          |      1|none  |     0|acc   |↑  |0.5719|±  |0.0283|
|  - professional_accounting            |      1|none  |     0|acc   |↑  |0.3617|±  |0.0287|
|  - professional_medicine              |      1|none  |     0|acc   |↑  |0.5551|±  |0.0302|
|  - virology                           |      1|none  |     0|acc   |↑  |0.4277|±  |0.0385|
| - social sciences                     |      2|none  |      |acc   |↑  |0.5128|±  |0.0088|
|  - econometrics                       |      1|none  |     0|acc   |↑  |0.2368|±  |0.0400|
|  - high_school_geography              |      1|none  |     0|acc   |↑  |0.5657|±  |0.0353|
|  - high_school_government_and_politics|      1|none  |     0|acc   |↑  |0.5337|±  |0.0360|
|  - high_school_macroeconomics         |      1|none  |     0|acc   |↑  |0.4077|±  |0.0249|
|  - high_school_microeconomics         |      1|none  |     0|acc   |↑  |0.4622|±  |0.0324|
|  - high_school_psychology             |      1|none  |     0|acc   |↑  |0.6312|±  |0.0207|
|  - human_sexuality                    |      1|none  |     0|acc   |↑  |0.5573|±  |0.0436|
|  - professional_psychology            |      1|none  |     0|acc   |↑  |0.4248|±  |0.0200|
|  - public_relations                   |      1|none  |     0|acc   |↑  |0.4909|±  |0.0479|
|  - security_studies                   |      1|none  |     0|acc   |↑  |0.5388|±  |0.0319|
|  - sociology                          |      1|none  |     0|acc   |↑  |0.6567|±  |0.0336|
|  - us_foreign_policy                  |      1|none  |     0|acc   |↑  |0.7200|±  |0.0451|
| - stem                                |      2|none  |      |acc   |↑  |0.3838|±  |0.0085|
|  - abstract_algebra                   |      1|none  |     0|acc   |↑  |0.2300|±  |0.0423|
|  - anatomy                            |      1|none  |     0|acc   |↑  |0.4741|±  |0.0431|
|  - astronomy                          |      1|none  |     0|acc   |↑  |0.5592|±  |0.0404|
|  - college_biology                    |      1|none  |     0|acc   |↑  |0.5000|±  |0.0418|
|  - college_chemistry                  |      1|none  |     0|acc   |↑  |0.3600|±  |0.0482|
|  - college_computer_science           |      1|none  |     0|acc   |↑  |0.3200|±  |0.0469|
|  - college_mathematics                |      1|none  |     0|acc   |↑  |0.2800|±  |0.0451|
|  - college_physics                    |      1|none  |     0|acc   |↑  |0.2843|±  |0.0449|
|  - computer_security                  |      1|none  |     0|acc   |↑  |0.4700|±  |0.0502|
|  - conceptual_physics                 |      1|none  |     0|acc   |↑  |0.4426|±  |0.0325|
|  - electrical_engineering             |      1|none  |     0|acc   |↑  |0.5448|±  |0.0415|
|  - elementary_mathematics             |      1|none  |     0|acc   |↑  |0.2884|±  |0.0233|
|  - high_school_biology                |      1|none  |     0|acc   |↑  |0.4935|±  |0.0284|
|  - high_school_chemistry              |      1|none  |     0|acc   |↑  |0.3596|±  |0.0338|
|  - high_school_computer_science       |      1|none  |     0|acc   |↑  |0.4600|±  |0.0501|
|  - high_school_mathematics            |      1|none  |     0|acc   |↑  |0.2704|±  |0.0271|
|  - high_school_physics                |      1|none  |     0|acc   |↑  |0.3113|±  |0.0378|
|  - high_school_statistics             |      1|none  |     0|acc   |↑  |0.3426|±  |0.0324|
|  - machine_learning                   |      1|none  |     0|acc   |↑  |0.3214|±  |0.0443|

|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|------------------|------:|------|------|------|---|-----:|---|-----:|
|mmlu              |      2|none  |      |acc   |↑  |0.4612|±  |0.0041|
| - humanities     |      2|none  |      |acc   |↑  |0.4397|±  |0.0071|
| - other          |      2|none  |      |acc   |↑  |0.5211|±  |0.0088|
| - social sciences|      2|none  |      |acc   |↑  |0.5128|±  |0.0088|
| - stem           |      2|none  |      |acc   |↑  |0.3838|±  |0.0085|

