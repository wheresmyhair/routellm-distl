INFO 04-10 20:53:47 [__init__.py:239] Automatically detected platform cuda.
INFO:lm_eval.__main__:Selected Tasks: ['minerva_math']
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Initializing vllm model, with arguments: {'pretrained': 'google/gemma-3-4b-it'}
INFO 04-10 20:53:57 [config.py:604] This model supports multiple tasks: {'embed', 'reward', 'score', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 04-10 20:53:57 [config.py:1797] Chunked prefill is enabled with max_num_batched_tokens=16384.
WARNING 04-10 20:53:59 [utils.py:2289] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized
INFO 04-10 20:54:04 [__init__.py:239] Automatically detected platform cuda.
INFO 04-10 20:54:05 [core.py:61] Initializing a V1 LLM engine (v0.8.3rc2.dev107+g0d4d06fe2) with config: model='google/gemma-3-4b-it', speculative_config=None, tokenizer='google/gemma-3-4b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1234, served_model_name=google/gemma-3-4b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 04-10 20:54:05 [utils.py:2429] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efa2796e110>
INFO 04-10 20:54:06 [parallel_state.py:957] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 04-10 20:54:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 04-10 20:54:12 [gpu_model_runner.py:1277] Starting to load model google/gemma-3-4b-it...
INFO 04-10 20:54:12 [config.py:3351] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 04-10 20:54:12 [topk_topp_sampler.py:44] Currently, FlashInfer top-p & top-k sampling sampler is disabled because FlashInfer>=v0.2.3 is not backward compatible. Falling back to the PyTorch-native implementation of top-p & top-k sampling.
INFO 04-10 20:54:12 [weight_utils.py:265] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.00it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.12it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.10it/s]

INFO 04-10 20:54:14 [loader.py:458] Loading weights took 1.92 seconds
INFO 04-10 20:54:14 [gpu_model_runner.py:1292] Model loading took 8.5833 GiB and 2.409956 seconds
INFO 04-10 20:54:14 [gpu_model_runner.py:1561] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 64 image items of the maximum feature size.
INFO 04-10 20:54:24 [backends.py:416] Using cache directory: /home/yizhenjia/.cache/vllm/torch_compile_cache/1e3a621052/rank_0_0 for vLLM's torch.compile
INFO 04-10 20:54:24 [backends.py:426] Dynamo bytecode transform time: 7.56 s
INFO 04-10 20:54:24 [backends.py:115] Directly load the compiled graph for shape None from the cache
INFO 04-10 20:54:36 [monitor.py:33] torch.compile takes 7.56 s in total
INFO 04-10 20:54:37 [kv_cache_utils.py:634] GPU KV cache size: 387,744 tokens
INFO 04-10 20:54:37 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 2.96x
INFO 04-10 20:55:03 [gpu_model_runner.py:1627] Graph capturing finished in 26 secs, took 2.07 GiB
INFO 04-10 20:55:03 [core.py:162] init engine (profile, create kv cache, warmup model) took 48.55 seconds
INFO 04-10 20:55:03 [core_client.py:435] Core engine process 0 ready.
INFO:lm_eval.models.vllm_causallms:Found 'gemma' in model name, a BOS token will be used as Gemma series models underperform without it.
INFO:lm_eval.evaluator:minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_algebra from 4 to 0
INFO:lm_eval.evaluator:minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 0
INFO:lm_eval.evaluator:minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_geometry from 4 to 0
INFO:lm_eval.evaluator:minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 0
INFO:lm_eval.evaluator:minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_num_theory from 4 to 0
INFO:lm_eval.evaluator:minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 0
INFO:lm_eval.evaluator:minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of minerva_math_precalc from 4 to 0
INFO:lm_eval.api.task:Building contexts for minerva_math_algebra on rank 0...
  0%|          | 0/1187 [00:00<?, ?it/s]100%|██████████| 1187/1187 [00:00<00:00, 138978.84it/s]
INFO:lm_eval.api.task:Building contexts for minerva_math_counting_and_prob on rank 0...
  0%|          | 0/474 [00:00<?, ?it/s]100%|██████████| 474/474 [00:00<00:00, 135697.23it/s]
INFO:lm_eval.api.task:Building contexts for minerva_math_geometry on rank 0...
  0%|          | 0/479 [00:00<?, ?it/s]100%|██████████| 479/479 [00:00<00:00, 143198.26it/s]
INFO:lm_eval.api.task:Building contexts for minerva_math_intermediate_algebra on rank 0...
  0%|          | 0/903 [00:00<?, ?it/s]100%|██████████| 903/903 [00:00<00:00, 142091.78it/s]
INFO:lm_eval.api.task:Building contexts for minerva_math_num_theory on rank 0...
  0%|          | 0/540 [00:00<?, ?it/s]100%|██████████| 540/540 [00:00<00:00, 146058.18it/s]
INFO:lm_eval.api.task:Building contexts for minerva_math_prealgebra on rank 0...
  0%|          | 0/871 [00:00<?, ?it/s]100%|██████████| 871/871 [00:00<00:00, 138312.15it/s]
INFO:lm_eval.api.task:Building contexts for minerva_math_precalc on rank 0...
  0%|          | 0/546 [00:00<?, ?it/s]100%|██████████| 546/546 [00:00<00:00, 136363.58it/s]
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/5000 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/5000 [00:02<3:06:37,  2.24s/it]Running generate_until requests:   1%|          | 33/5000 [00:04<09:00,  9.19it/s] Running generate_until requests:   1%|▏         | 65/5000 [00:06<06:36, 12.43it/s]Running generate_until requests:   2%|▏         | 97/5000 [00:08<05:47, 14.11it/s]Running generate_until requests:   3%|▎         | 129/5000 [00:09<05:21, 15.13it/s]Running generate_until requests:   3%|▎         | 161/5000 [00:11<05:06, 15.81it/s]Running generate_until requests:   4%|▍         | 193/5000 [00:13<04:55, 16.29it/s]Running generate_until requests:   4%|▍         | 225/5000 [00:15<04:46, 16.66it/s]Running generate_until requests:   5%|▌         | 257/5000 [00:17<04:39, 16.95it/s]Running generate_until requests:   6%|▌         | 289/5000 [00:19<04:34, 17.18it/s]Running generate_until requests:   6%|▋         | 321/5000 [00:20<04:29, 17.38it/s]Running generate_until requests:   7%|▋         | 353/5000 [00:22<04:25, 17.53it/s]Running generate_until requests:   8%|▊         | 385/5000 [00:24<04:21, 17.65it/s]Running generate_until requests:   8%|▊         | 417/5000 [00:26<04:18, 17.74it/s]Running generate_until requests:   9%|▉         | 449/5000 [00:28<04:14, 17.85it/s]Running generate_until requests:  10%|▉         | 481/5000 [00:29<04:11, 17.95it/s]Running generate_until requests:  10%|█         | 513/5000 [00:31<04:08, 18.03it/s]Running generate_until requests:  11%|█         | 545/5000 [00:33<04:05, 18.12it/s]Running generate_until requests:  12%|█▏        | 577/5000 [00:35<04:03, 18.20it/s]Running generate_until requests:  12%|█▏        | 609/5000 [00:36<04:00, 18.27it/s]Running generate_until requests:  13%|█▎        | 641/5000 [00:38<03:58, 18.31it/s]Running generate_until requests:  13%|█▎        | 673/5000 [00:40<03:55, 18.36it/s]Running generate_until requests:  14%|█▍        | 705/5000 [00:41<03:53, 18.39it/s]Running generate_until requests:  15%|█▍        | 737/5000 [00:43<03:51, 18.42it/s]Running generate_until requests:  15%|█▌        | 769/5000 [00:45<03:49, 18.44it/s]Running generate_until requests:  16%|█▌        | 801/5000 [00:47<03:47, 18.47it/s]Running generate_until requests:  17%|█▋        | 833/5000 [00:48<03:45, 18.50it/s]Running generate_until requests:  17%|█▋        | 865/5000 [00:50<03:43, 18.51it/s]Running generate_until requests:  18%|█▊        | 897/5000 [00:52<03:41, 18.53it/s]Running generate_until requests:  19%|█▊        | 929/5000 [00:54<03:39, 18.54it/s]Running generate_until requests:  19%|█▉        | 961/5000 [00:55<03:37, 18.56it/s]Running generate_until requests:  20%|█▉        | 993/5000 [00:57<03:35, 18.58it/s]Running generate_until requests:  20%|██        | 1025/5000 [00:59<03:34, 18.55it/s]Running generate_until requests:  21%|██        | 1057/5000 [01:00<03:32, 18.58it/s]Running generate_until requests:  22%|██▏       | 1089/5000 [01:02<03:30, 18.59it/s]Running generate_until requests:  22%|██▏       | 1121/5000 [01:04<03:28, 18.62it/s]Running generate_until requests:  23%|██▎       | 1153/5000 [01:06<03:26, 18.63it/s]Running generate_until requests:  24%|██▎       | 1185/5000 [01:07<03:24, 18.65it/s]Running generate_until requests:  24%|██▍       | 1217/5000 [01:09<03:22, 18.66it/s]Running generate_until requests:  25%|██▍       | 1249/5000 [01:11<03:20, 18.68it/s]Running generate_until requests:  26%|██▌       | 1281/5000 [01:12<03:19, 18.68it/s]Running generate_until requests:  26%|██▋       | 1313/5000 [01:14<03:17, 18.70it/s]Running generate_until requests:  27%|██▋       | 1345/5000 [01:16<03:15, 18.71it/s]Running generate_until requests:  28%|██▊       | 1377/5000 [01:18<03:13, 18.72it/s]Running generate_until requests:  28%|██▊       | 1409/5000 [01:19<03:11, 18.73it/s]Running generate_until requests:  29%|██▉       | 1441/5000 [01:21<03:09, 18.74it/s]Running generate_until requests:  29%|██▉       | 1473/5000 [01:23<03:08, 18.74it/s]Running generate_until requests:  30%|███       | 1505/5000 [01:24<03:06, 18.75it/s]Running generate_until requests:  31%|███       | 1537/5000 [01:26<03:04, 18.76it/s]Running generate_until requests:  31%|███▏      | 1569/5000 [01:28<03:02, 18.77it/s]Running generate_until requests:  32%|███▏      | 1601/5000 [01:29<03:00, 18.78it/s]Running generate_until requests:  33%|███▎      | 1633/5000 [01:31<02:59, 18.74it/s]Running generate_until requests:  33%|███▎      | 1665/5000 [01:33<02:57, 18.76it/s]Running generate_until requests:  34%|███▍      | 1697/5000 [01:35<02:56, 18.76it/s]Running generate_until requests:  35%|███▍      | 1729/5000 [01:36<02:54, 18.77it/s]Running generate_until requests:  35%|███▌      | 1761/5000 [01:38<02:52, 18.78it/s]Running generate_until requests:  36%|███▌      | 1793/5000 [01:40<02:50, 18.79it/s]Running generate_until requests:  36%|███▋      | 1825/5000 [01:41<02:48, 18.79it/s]Running generate_until requests:  37%|███▋      | 1857/5000 [01:43<02:47, 18.79it/s]Running generate_until requests:  38%|███▊      | 1889/5000 [01:45<02:45, 18.80it/s]Running generate_until requests:  38%|███▊      | 1921/5000 [01:47<02:43, 18.81it/s]Running generate_until requests:  39%|███▉      | 1953/5000 [01:48<02:42, 18.81it/s]Running generate_until requests:  40%|███▉      | 1985/5000 [01:50<02:40, 18.83it/s]Running generate_until requests:  40%|████      | 2017/5000 [01:52<02:38, 18.84it/s]Running generate_until requests:  41%|████      | 2049/5000 [01:53<02:36, 18.84it/s]Running generate_until requests:  42%|████▏     | 2081/5000 [01:55<02:34, 18.85it/s]Running generate_until requests:  42%|████▏     | 2113/5000 [01:57<02:33, 18.85it/s]Running generate_until requests:  43%|████▎     | 2145/5000 [01:58<02:31, 18.86it/s]Running generate_until requests:  44%|████▎     | 2177/5000 [02:00<02:29, 18.87it/s]Running generate_until requests:  44%|████▍     | 2209/5000 [02:02<02:27, 18.88it/s]Running generate_until requests:  45%|████▍     | 2241/5000 [02:03<02:26, 18.82it/s]Running generate_until requests:  45%|████▌     | 2273/5000 [02:05<02:24, 18.85it/s]Running generate_until requests:  46%|████▌     | 2305/5000 [02:07<02:22, 18.86it/s]Running generate_until requests:  47%|████▋     | 2337/5000 [02:09<02:21, 18.88it/s]Running generate_until requests:  47%|████▋     | 2369/5000 [02:10<02:19, 18.89it/s]Running generate_until requests:  48%|████▊     | 2401/5000 [02:12<02:17, 18.89it/s]Running generate_until requests:  49%|████▊     | 2433/5000 [02:14<02:15, 18.91it/s]Running generate_until requests:  49%|████▉     | 2465/5000 [02:15<02:14, 18.91it/s]Running generate_until requests:  50%|████▉     | 2497/5000 [02:17<02:12, 18.92it/s]Running generate_until requests:  51%|█████     | 2529/5000 [02:19<02:10, 18.92it/s]Running generate_until requests:  51%|█████     | 2561/5000 [02:20<02:08, 18.92it/s]Running generate_until requests:  52%|█████▏    | 2593/5000 [02:22<02:07, 18.92it/s]Running generate_until requests:  52%|█████▎    | 2625/5000 [02:24<02:05, 18.91it/s]Running generate_until requests:  53%|█████▎    | 2657/5000 [02:25<02:03, 18.92it/s]Running generate_until requests:  54%|█████▍    | 2689/5000 [02:27<02:02, 18.90it/s]Running generate_until requests:  54%|█████▍    | 2721/5000 [02:29<02:00, 18.90it/s]Running generate_until requests:  55%|█████▌    | 2753/5000 [02:31<01:58, 18.91it/s]Running generate_until requests:  56%|█████▌    | 2785/5000 [02:32<01:56, 19.03it/s]Running generate_until requests:  56%|█████▋    | 2817/5000 [02:34<01:53, 19.15it/s]Running generate_until requests:  57%|█████▋    | 2849/5000 [02:36<01:51, 19.25it/s]Running generate_until requests:  58%|█████▊    | 2881/5000 [02:37<01:49, 19.27it/s]Running generate_until requests:  58%|█████▊    | 2913/5000 [02:39<01:48, 19.32it/s]Running generate_until requests:  59%|█████▉    | 2945/5000 [02:40<01:46, 19.37it/s]Running generate_until requests:  60%|█████▉    | 2977/5000 [02:42<01:44, 19.40it/s]Running generate_until requests:  60%|██████    | 3009/5000 [02:44<01:42, 19.42it/s]Running generate_until requests:  61%|██████    | 3041/5000 [02:45<01:40, 19.43it/s]Running generate_until requests:  61%|██████▏   | 3073/5000 [02:47<01:39, 19.44it/s]Running generate_until requests:  62%|██████▏   | 3105/5000 [02:49<01:37, 19.45it/s]Running generate_until requests:  63%|██████▎   | 3137/5000 [02:50<01:35, 19.46it/s]Running generate_until requests:  63%|██████▎   | 3169/5000 [02:52<01:34, 19.48it/s]Running generate_until requests:  64%|██████▍   | 3201/5000 [02:54<01:32, 19.48it/s]Running generate_until requests:  65%|██████▍   | 3233/5000 [02:55<01:30, 19.49it/s]Running generate_until requests:  65%|██████▌   | 3265/5000 [02:57<01:28, 19.50it/s]Running generate_until requests:  66%|██████▌   | 3297/5000 [02:59<01:27, 19.50it/s]Running generate_until requests:  67%|██████▋   | 3329/5000 [03:00<01:25, 19.50it/s]Running generate_until requests:  67%|██████▋   | 3361/5000 [03:02<01:23, 19.51it/s]Running generate_until requests:  68%|██████▊   | 3393/5000 [03:03<01:22, 19.52it/s]Running generate_until requests:  68%|██████▊   | 3425/5000 [03:05<01:20, 19.53it/s]Running generate_until requests:  69%|██████▉   | 3457/5000 [03:07<01:18, 19.54it/s]Running generate_until requests:  70%|██████▉   | 3489/5000 [03:08<01:17, 19.56it/s]Running generate_until requests:  70%|███████   | 3521/5000 [03:10<01:15, 19.57it/s]Running generate_until requests:  71%|███████   | 3553/5000 [03:12<01:13, 19.56it/s]Running generate_until requests:  72%|███████▏  | 3585/5000 [03:13<01:12, 19.56it/s]Running generate_until requests:  72%|███████▏  | 3617/5000 [03:15<01:10, 19.56it/s]Running generate_until requests:  73%|███████▎  | 3649/5000 [03:17<01:09, 19.54it/s]Running generate_until requests:  74%|███████▎  | 3681/5000 [03:18<01:07, 19.54it/s]Running generate_until requests:  74%|███████▍  | 3713/5000 [03:20<01:05, 19.53it/s]Running generate_until requests:  75%|███████▍  | 3745/5000 [03:21<01:04, 19.54it/s]Running generate_until requests:  76%|███████▌  | 3777/5000 [03:23<01:02, 19.54it/s]Running generate_until requests:  76%|███████▌  | 3809/5000 [03:25<01:01, 19.51it/s]Running generate_until requests:  77%|███████▋  | 3841/5000 [03:26<00:59, 19.50it/s]Running generate_until requests:  77%|███████▋  | 3873/5000 [03:28<00:57, 19.53it/s]Running generate_until requests:  78%|███████▊  | 3905/5000 [03:30<00:56, 19.50it/s]Running generate_until requests:  79%|███████▊  | 3937/5000 [03:31<00:54, 19.52it/s]Running generate_until requests:  79%|███████▉  | 3969/5000 [03:33<00:52, 19.54it/s]Running generate_until requests:  80%|████████  | 4001/5000 [03:35<00:51, 19.55it/s]Running generate_until requests:  81%|████████  | 4033/5000 [03:36<00:49, 19.56it/s]Running generate_until requests:  81%|████████▏ | 4065/5000 [03:38<00:47, 19.57it/s]Running generate_until requests:  82%|████████▏ | 4097/5000 [03:39<00:46, 19.57it/s]Running generate_until requests:  83%|████████▎ | 4129/5000 [03:41<00:44, 19.60it/s]Running generate_until requests:  83%|████████▎ | 4161/5000 [03:43<00:42, 19.53it/s]Running generate_until requests:  84%|████████▍ | 4193/5000 [03:44<00:41, 19.52it/s]Running generate_until requests:  84%|████████▍ | 4225/5000 [03:46<00:39, 19.52it/s]Running generate_until requests:  85%|████████▌ | 4257/5000 [03:48<00:38, 19.52it/s]Running generate_until requests:  86%|████████▌ | 4289/5000 [03:49<00:36, 19.55it/s]Running generate_until requests:  86%|████████▋ | 4321/5000 [03:51<00:34, 19.58it/s]Running generate_until requests:  87%|████████▋ | 4353/5000 [03:53<00:33, 19.60it/s]Running generate_until requests:  88%|████████▊ | 4385/5000 [03:54<00:31, 19.63it/s]Running generate_until requests:  88%|████████▊ | 4417/5000 [03:56<00:29, 19.65it/s]Running generate_until requests:  89%|████████▉ | 4449/5000 [03:57<00:28, 19.63it/s]Running generate_until requests:  90%|████████▉ | 4481/5000 [03:59<00:26, 19.60it/s]Running generate_until requests:  90%|█████████ | 4513/5000 [04:01<00:24, 19.58it/s]Running generate_until requests:  91%|█████████ | 4545/5000 [04:02<00:23, 19.60it/s]Running generate_until requests:  92%|█████████▏| 4577/5000 [04:04<00:21, 19.61it/s]Running generate_until requests:  92%|█████████▏| 4609/5000 [04:06<00:19, 19.62it/s]Running generate_until requests:  93%|█████████▎| 4641/5000 [04:07<00:18, 19.63it/s]Running generate_until requests:  93%|█████████▎| 4673/5000 [04:09<00:16, 19.64it/s]Running generate_until requests:  94%|█████████▍| 4705/5000 [04:10<00:15, 19.64it/s]Running generate_until requests:  95%|█████████▍| 4737/5000 [04:12<00:13, 19.65it/s]Running generate_until requests:  95%|█████████▌| 4769/5000 [04:14<00:11, 19.68it/s]Running generate_until requests:  96%|█████████▌| 4801/5000 [04:15<00:10, 19.69it/s]Running generate_until requests:  97%|█████████▋| 4833/5000 [04:17<00:08, 19.67it/s]Running generate_until requests:  97%|█████████▋| 4865/5000 [04:19<00:07, 18.19it/s]Running generate_until requests:  98%|█████████▊| 4897/5000 [04:21<00:05, 18.63it/s]Running generate_until requests:  99%|█████████▊| 4929/5000 [04:22<00:03, 18.94it/s]Running generate_until requests:  99%|█████████▉| 4961/5000 [04:24<00:02, 19.15it/s]Running generate_until requests: 100%|█████████▉| 4993/5000 [04:25<00:00, 19.57it/s]Running generate_until requests: 100%|██████████| 5000/5000 [04:25<00:00, 18.80it/s]
INFO:lm_eval.loggers.evaluation_tracker:Saving results aggregated
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_algebra
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_counting_and_prob
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_geometry
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_intermediate_algebra
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_num_theory
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_prealgebra
INFO:lm_eval.loggers.evaluation_tracker:Saving per-sample results for: minerva_math_precalc
vllm (pretrained=google/gemma-3-4b-it), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 32
|               Tasks                |Version|Filter|n-shot|  Metric   |   |Value |   |Stderr|
|------------------------------------|------:|------|-----:|-----------|---|-----:|---|-----:|
|minerva_math                        |      1|none  |      |exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |      |math_verify|↑  |0.1024|±  |0.0042|
| - minerva_math_algebra             |      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.1727|±  |0.0110|
| - minerva_math_counting_and_prob   |      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.0970|±  |0.0136|
| - minerva_math_geometry            |      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.0689|±  |0.0116|
| - minerva_math_intermediate_algebra|      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.0443|±  |0.0069|
| - minerva_math_num_theory          |      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.0630|±  |0.0105|
| - minerva_math_prealgebra          |      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.1561|±  |0.0123|
| - minerva_math_precalc             |      2|none  |     0|exact_match|↑  |0.0000|±  |0.0000|
|                                    |       |none  |     0|math_verify|↑  |0.0330|±  |0.0076|

|   Groups   |Version|Filter|n-shot|  Metric   |   |Value |   |Stderr|
|------------|------:|------|------|-----------|---|-----:|---|-----:|
|minerva_math|      1|none  |      |exact_match|↑  |0.0000|±  |0.0000|
|            |       |none  |      |math_verify|↑  |0.1024|±  |0.0042|

[rank0]:[W410 21:03:16.185036617 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
